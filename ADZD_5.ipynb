{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04df9b1",
   "metadata": {},
   "source": [
    "### Wczytać graf Facebooka, krawędzie z pliku musae_facebook_edges.csv, atrybuty page_name oraz page_type z pliku musae_facebook_target.csv.  Policzyć liczbę krawędzi i wierzchołków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801b9eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://2ba31a446ddf:4040\n",
       "SparkContext available as 'sc' (version = 3.2.0, master = local[*], app id = local-1638976742312)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n",
       "import org.apache.spark.sql.functions.col\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.functions.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b1e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|id_1| id_2|\n",
      "+----+-----+\n",
      "|   0|18427|\n",
      "|   1|21708|\n",
      "|   1|22208|\n",
      "|   1|22171|\n",
      "|   1| 6829|\n",
      "|   1|16590|\n",
      "|   1|20135|\n",
      "|   1| 8894|\n",
      "|   1|15785|\n",
      "|   1|10281|\n",
      "|   1|22265|\n",
      "|   1| 7136|\n",
      "|   1|22405|\n",
      "|   1|10379|\n",
      "|   1|13737|\n",
      "|   1| 8533|\n",
      "|   1|14344|\n",
      "|   1| 2812|\n",
      "|   1| 5755|\n",
      "|   1|16260|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "edgesDF: org.apache.spark.sql.DataFrame = [id_1: int, id_2: int]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val edgesDF = spark.read.format(\"csv\")\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".load(\"musae_facebook_edges.csv\")\n",
    "edgesDF.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f90850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|           page_name| page_type|\n",
      "+--------------------+----------+\n",
      "|The Voice of Chin...|    tvshow|\n",
      "|U.S. Consulate Ge...|government|\n",
      "|                ESET|   company|\n",
      "|Consulate General...|government|\n",
      "|Mark Bailey MP - ...|politician|\n",
      "| Victor Dominello MP|politician|\n",
      "|Jean-Claude Poissant|politician|\n",
      "|Deputado Ademir C...|politician|\n",
      "|T.C. Mezar-ı Şeri...|government|\n",
      "|Army ROTC Fightin...|government|\n",
      "| NASA Student Launch|government|\n",
      "|       Eliziane Gama|politician|\n",
      "|     Socialstyrelsen|government|\n",
      "|Brisbane Water LA...|government|\n",
      "|NASA's Marshall S...|government|\n",
      "|Municipio de Loma...|government|\n",
      "|  Die Techniker (TK)|   company|\n",
      "|     Digvijaya Singh|politician|\n",
      "|1st Armored Divis...|government|\n",
      "|           Shapeways|   company|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "verticesDF: org.apache.spark.sql.DataFrame = [id: int, facebook_id: bigint ... 2 more fields]\n",
       "vert_df: org.apache.spark.sql.DataFrame = [page_name: string, page_type: string]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val verticesDF = spark.read.format(\"csv\")\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".load(\"musae_facebook_target.csv\")\n",
    "\n",
    "val vert_df = verticesDF.select(\"page_name\",\"page_type\" )\n",
    "vert_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb29733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vertices: org.apache.spark.rdd.RDD[(org.apache.spark.graphx.VertexId, (String, String))] = MapPartitionsRDD[33] at map at <console>:32\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Vertices: RDD[(VertexId, (String, String))] = verticesDF\n",
    "  .select(col(\"id\").cast(\"long\"), col(\"page_name\"), col(\"page_type\"))\n",
    "  .rdd\n",
    "  .map(row => (row.getLong(0), (row.getString(1), row.getString(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250837a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edges: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Long]] = MapPartitionsRDD[40] at map at <console>:32\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Edges: RDD[Edge[Long]] = edgesDF\n",
    "  .select(col(\"id_1\").cast(\"long\"), col(\"id_2\").cast(\"long\"))\n",
    "  .rdd\n",
    "  .map(row => Edge(row.getLong(0), row.getLong(1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b29eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultV: (String, String) = (NameMissing,TypeMissing)\n",
       "myGraph: org.apache.spark.graphx.Graph[(String, String),Long] = org.apache.spark.graphx.impl.GraphImpl@2aa5d05d\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val defaultV = (\"NameMissing\", \"TypeMissing\")\n",
    "val myGraph = Graph(Vertices, Edges, defaultV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a419f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Vertices: 22470\n",
      "Total Number of Edges: 171002\n"
     ]
    }
   ],
   "source": [
    "println(\"Total Number of Vertices: \" + myGraph.numVertices)\n",
    "println(\"Total Number of Edges: \" + myGraph.numEdges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25818d07",
   "metadata": {},
   "source": [
    "### Sprawdzić czy graf jest spójny. Czy dwa podgrafy utworzone dla typów strony politician oraz company też są spójne? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b1e064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Boolean = true\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGraph.vertices.count() == myGraph.connectedComponents().vertices.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491f3f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_subgraph1: org.apache.spark.graphx.Graph[(String, String),Long] = org.apache.spark.graphx.impl.GraphImpl@125475f3\n",
       "res4: Boolean = true\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val my_subgraph1 = myGraph.subgraph(vpred = (id, attr) => attr._2 == \"politician\")\n",
    "my_subgraph1.vertices.count() == my_subgraph1.connectedComponents().vertices.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72acf7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_subgraph2: org.apache.spark.graphx.Graph[(String, String),Long] = org.apache.spark.graphx.impl.GraphImpl@ffbdeaa\n",
       "res5: Boolean = true\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val my_subgraph2 = myGraph.subgraph(vpred = (id, attr) => attr._2 == \"company\")\n",
    "my_subgraph2.vertices.count() == my_subgraph2.connectedComponents().vertices.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c888a",
   "metadata": {},
   "source": [
    "### Spośród 1000 stron o najwyższym PageRank znaleźć 50 takich (wypisać page_name i page_type), które mają najmniej połączeń oraz 50 o największej liczbie połączeń. Który typ strony był dominujący w każdej z tych kategorii? Narysować wykres zależności PageRank od liczby krawędzi dla wierzchołków (scatter plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f91b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ranks: org.apache.spark.graphx.VertexRDD[Double] = VertexRDDImpl[1844] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ranks = myGraph.pageRank(0.0001).vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7804c3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: org.apache.spark.graphx.VertexRDD[Double] = VertexRDDImpl[1844] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc55d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb404726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1833d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab4a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7b81a12",
   "metadata": {},
   "source": [
    "### Korzystając z Pregel API zaimplementować następujący algorytm. W pierwszym kroku wybrana strona publikuje post fake news. W kolejnym kroku ten post publikowany jest przez ⅓ losowo wybranych kontaktów tej strony. W dalszych krokach, dla każdej strony, która opublikowała już ten post, losowo wybrane ⅓ jej kontaktów publikuje go u siebie. Pokazać jak zmienia się liczba stron które opublikowały post w zależności od liczby kroków. (2 p.)\n",
    "### Opcjonalnie: Sprawdzić powyższą zależność dla współczynnika innego niż 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e6135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
